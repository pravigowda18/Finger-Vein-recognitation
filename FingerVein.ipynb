{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d5a7b48-0666-4f09-8669-cf7e2faecc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_images_from_directory(directory, target_size=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_labels = sorted(os.listdir(directory))  # Each person_name folder is a class label\n",
    "    label_map = {label: idx for idx, label in enumerate(class_labels)}\n",
    "    \n",
    "    for person_name in class_labels:\n",
    "        person_path = os.path.join(directory, person_name)\n",
    "        if os.path.isdir(person_path):\n",
    "            for hand in ['left', 'right']:\n",
    "                hand_path = os.path.join(person_path, hand)\n",
    "                if os.path.isdir(hand_path):\n",
    "                    for finger in ['middle', 'ring', 'index']:\n",
    "                        finger_path = os.path.join(hand_path, finger)\n",
    "                        if os.path.isdir(finger_path):\n",
    "                            for filename in os.listdir(finger_path):\n",
    "                                if filename.endswith('.bmp'):\n",
    "                                    img_path = os.path.join(finger_path, filename)\n",
    "                                    try:\n",
    "                                        # img = load_img(img_path, target_size=target_size)  # Load image\n",
    "                                        img = cv2.imread(img_path) \n",
    "                                        img = cv2.resize(img, (224,224)) \n",
    "                                        # _,img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "                                        img_array = img_to_array(img) / 255.0  # Normalize image\n",
    "                                        images.append(img_array)\n",
    "                                        labels.append(label_map[person_name])\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error loading image {img_path}: {e}\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Example usage\n",
    "directory = r\"E:\\Machine Learning Project\\Finger Vein Database\"  # Update with the actual path\n",
    "X, y = load_images_from_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceebe177-cb5c-4199-a9dc-9d7c4b2a5ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8e53edc-ad2e-4382-9ef3-dcee18ebb6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Train set size: (1425, 224, 224, 3)\n",
      "Test set size: (357, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset loaded successfully!\")\n",
    "print(\"Train set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b52966a-ae75-4efb-ad97-825743be20ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction completed!\n",
      "Feature shape: (1425, 26258)\n"
     ]
    }
   ],
   "source": [
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage.filters import gabor\n",
    "import numpy as np\n",
    "from skimage.color import rgb2gray  # To convert RGB to grayscale\n",
    "\n",
    "def extract_features(images):\n",
    "    features = []\n",
    "    \n",
    "    for img in images:\n",
    "        # Convert RGB image to grayscale\n",
    "        img_gray = rgb2gray(img)  # Converts to 2D grayscale image\n",
    "        \n",
    "        # Convert to float32 and normalize to [0, 1]\n",
    "        img_gray = img_gray.astype(np.float32)  # No need to normalize again if using rgb2gray\n",
    "        \n",
    "        # Compute HOG features\n",
    "        try:\n",
    "            hog_features = hog(img_gray, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "        except Exception as e:\n",
    "            print(f\"HOG feature extraction failed for image {img.shape}: {e}\")\n",
    "            hog_features = np.zeros(0)  # Placeholder for failed extraction\n",
    "        \n",
    "        # Compute LBP features\n",
    "        lbp = local_binary_pattern(img_gray, P=8, R=1, method=\"uniform\")\n",
    "        lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), density=True)  # Normalize histogram\n",
    "        \n",
    "        # Compute Gabor features\n",
    "        try:\n",
    "            gabor_real, gabor_imag = gabor(img_gray, frequency=0.6)\n",
    "            gabor_features = [np.mean(gabor_real), np.var(gabor_real), np.mean(gabor_imag), np.var(gabor_imag)]\n",
    "        except Exception as e:\n",
    "            print(f\"Gabor feature extraction failed for image {img.shape}: {e}\")\n",
    "            gabor_features = [0, 0, 0, 0]  # Placeholder for failed extraction\n",
    "        \n",
    "        # Concatenate all features\n",
    "        feature_vector = np.hstack([hog_features, lbp_hist, gabor_features])\n",
    "        features.append(feature_vector)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# Extract features from X_train\n",
    "X_train_features = extract_features(X_train)\n",
    "\n",
    "print(\"Feature extraction completed!\")\n",
    "print(\"Feature shape:\", X_train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "966825c4-cb11-4d1f-af73-7951b31001c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 556ms/step - accuracy: 0.0139 - loss: 5.8400 - val_accuracy: 0.0421 - val_loss: 3.8977\n",
      "Epoch 2/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 547ms/step - accuracy: 0.0290 - loss: 4.0788 - val_accuracy: 0.0561 - val_loss: 3.8586\n",
      "Epoch 3/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 546ms/step - accuracy: 0.0317 - loss: 3.9705 - val_accuracy: 0.0386 - val_loss: 3.8425\n",
      "Epoch 4/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 547ms/step - accuracy: 0.0408 - loss: 3.9092 - val_accuracy: 0.0561 - val_loss: 3.7968\n",
      "Epoch 5/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 550ms/step - accuracy: 0.0411 - loss: 3.8495 - val_accuracy: 0.0561 - val_loss: 3.6657\n",
      "Epoch 6/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 560ms/step - accuracy: 0.0494 - loss: 3.7659 - val_accuracy: 0.0667 - val_loss: 3.6351\n",
      "Epoch 7/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 545ms/step - accuracy: 0.0581 - loss: 3.6926 - val_accuracy: 0.0561 - val_loss: 3.5082\n",
      "Epoch 8/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 547ms/step - accuracy: 0.0519 - loss: 3.5798 - val_accuracy: 0.0772 - val_loss: 3.4598\n",
      "Epoch 9/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 549ms/step - accuracy: 0.0805 - loss: 3.4954 - val_accuracy: 0.0842 - val_loss: 3.3540\n",
      "Epoch 10/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 540ms/step - accuracy: 0.0568 - loss: 3.5052 - val_accuracy: 0.1298 - val_loss: 3.2986\n",
      "Epoch 11/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 557ms/step - accuracy: 0.0684 - loss: 3.3561 - val_accuracy: 0.2035 - val_loss: 3.1306\n",
      "Epoch 12/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 548ms/step - accuracy: 0.1072 - loss: 3.2928 - val_accuracy: 0.2140 - val_loss: 2.9640\n",
      "Epoch 13/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 549ms/step - accuracy: 0.1230 - loss: 3.1509 - val_accuracy: 0.2877 - val_loss: 2.7850\n",
      "Epoch 14/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 580ms/step - accuracy: 0.1371 - loss: 3.0914 - val_accuracy: 0.2737 - val_loss: 2.8100\n",
      "Epoch 15/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 641ms/step - accuracy: 0.1582 - loss: 2.9732 - val_accuracy: 0.3123 - val_loss: 2.5840\n",
      "Epoch 16/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 622ms/step - accuracy: 0.1933 - loss: 2.8443 - val_accuracy: 0.3579 - val_loss: 2.4817\n",
      "Epoch 17/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 612ms/step - accuracy: 0.2140 - loss: 2.7410 - val_accuracy: 0.3860 - val_loss: 2.2641\n",
      "Epoch 18/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 599ms/step - accuracy: 0.1901 - loss: 2.7351 - val_accuracy: 0.4211 - val_loss: 2.2337\n",
      "Epoch 19/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 581ms/step - accuracy: 0.2228 - loss: 2.5754 - val_accuracy: 0.4281 - val_loss: 2.0937\n",
      "Epoch 20/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 586ms/step - accuracy: 0.2179 - loss: 2.5627 - val_accuracy: 0.4561 - val_loss: 2.1046\n",
      "Epoch 21/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 556ms/step - accuracy: 0.2624 - loss: 2.4204 - val_accuracy: 0.4632 - val_loss: 2.0224\n",
      "Epoch 22/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 534ms/step - accuracy: 0.2339 - loss: 2.4889 - val_accuracy: 0.5193 - val_loss: 1.9960\n",
      "Epoch 23/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 554ms/step - accuracy: 0.2643 - loss: 2.3911 - val_accuracy: 0.4912 - val_loss: 1.9805\n",
      "Epoch 24/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 530ms/step - accuracy: 0.3031 - loss: 2.2596 - val_accuracy: 0.5474 - val_loss: 1.8447\n",
      "Epoch 25/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 540ms/step - accuracy: 0.3250 - loss: 2.2198 - val_accuracy: 0.5614 - val_loss: 1.7805\n",
      "Epoch 26/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 531ms/step - accuracy: 0.2978 - loss: 2.2444 - val_accuracy: 0.5053 - val_loss: 1.6838\n",
      "Epoch 27/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 511ms/step - accuracy: 0.3028 - loss: 2.2614 - val_accuracy: 0.6035 - val_loss: 1.6607\n",
      "Epoch 28/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 512ms/step - accuracy: 0.3614 - loss: 2.0391 - val_accuracy: 0.5684 - val_loss: 1.6015\n",
      "Epoch 29/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 516ms/step - accuracy: 0.3409 - loss: 2.0869 - val_accuracy: 0.6526 - val_loss: 1.5350\n",
      "Epoch 30/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 511ms/step - accuracy: 0.3612 - loss: 2.0330 - val_accuracy: 0.6947 - val_loss: 1.4481\n",
      "Epoch 31/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 512ms/step - accuracy: 0.3500 - loss: 1.8876 - val_accuracy: 0.6211 - val_loss: 1.3624\n",
      "Epoch 32/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 512ms/step - accuracy: 0.3760 - loss: 1.9329 - val_accuracy: 0.6632 - val_loss: 1.3956\n",
      "Epoch 33/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 507ms/step - accuracy: 0.3557 - loss: 2.0058 - val_accuracy: 0.6702 - val_loss: 1.4316\n",
      "Epoch 34/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 507ms/step - accuracy: 0.3961 - loss: 1.8585 - val_accuracy: 0.7579 - val_loss: 1.2883\n",
      "Epoch 35/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 506ms/step - accuracy: 0.4005 - loss: 1.7896 - val_accuracy: 0.7544 - val_loss: 1.2746\n",
      "Epoch 36/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 503ms/step - accuracy: 0.3805 - loss: 1.9585 - val_accuracy: 0.7018 - val_loss: 1.2999\n",
      "Epoch 37/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 507ms/step - accuracy: 0.3963 - loss: 1.8416 - val_accuracy: 0.7368 - val_loss: 1.2769\n",
      "Epoch 38/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 516ms/step - accuracy: 0.3637 - loss: 1.9272 - val_accuracy: 0.7263 - val_loss: 1.2980\n",
      "Epoch 39/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 513ms/step - accuracy: 0.4203 - loss: 1.7716 - val_accuracy: 0.7193 - val_loss: 1.1813\n",
      "Epoch 40/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 520ms/step - accuracy: 0.4006 - loss: 1.8664 - val_accuracy: 0.7439 - val_loss: 1.2230\n",
      "Epoch 41/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 517ms/step - accuracy: 0.4118 - loss: 1.8569 - val_accuracy: 0.7544 - val_loss: 1.1437\n",
      "Epoch 42/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 511ms/step - accuracy: 0.4637 - loss: 1.6632 - val_accuracy: 0.8351 - val_loss: 1.0875\n",
      "Epoch 43/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 506ms/step - accuracy: 0.4178 - loss: 1.6790 - val_accuracy: 0.7719 - val_loss: 1.1215\n",
      "Epoch 44/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 505ms/step - accuracy: 0.4213 - loss: 1.7301 - val_accuracy: 0.7825 - val_loss: 1.1111\n",
      "Epoch 45/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 507ms/step - accuracy: 0.4498 - loss: 1.6837 - val_accuracy: 0.7860 - val_loss: 1.1528\n",
      "Epoch 46/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 510ms/step - accuracy: 0.4284 - loss: 1.6588 - val_accuracy: 0.8351 - val_loss: 1.0208\n",
      "Epoch 47/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 506ms/step - accuracy: 0.4086 - loss: 1.7417 - val_accuracy: 0.8105 - val_loss: 1.1083\n",
      "Epoch 48/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 505ms/step - accuracy: 0.4141 - loss: 1.8243 - val_accuracy: 0.7860 - val_loss: 1.1157\n",
      "Epoch 49/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 512ms/step - accuracy: 0.4370 - loss: 1.7191 - val_accuracy: 0.8246 - val_loss: 1.0311\n",
      "Epoch 50/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 514ms/step - accuracy: 0.4622 - loss: 1.5818 - val_accuracy: 0.8386 - val_loss: 0.9977\n",
      "Epoch 51/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 513ms/step - accuracy: 0.4672 - loss: 1.6272 - val_accuracy: 0.7895 - val_loss: 1.0612\n",
      "Epoch 52/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 513ms/step - accuracy: 0.4199 - loss: 1.7071 - val_accuracy: 0.7965 - val_loss: 1.0002\n",
      "Epoch 53/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 505ms/step - accuracy: 0.4559 - loss: 1.6100 - val_accuracy: 0.8105 - val_loss: 0.9615\n",
      "Epoch 54/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 530ms/step - accuracy: 0.4181 - loss: 1.6880 - val_accuracy: 0.8246 - val_loss: 0.9454\n",
      "Epoch 55/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 516ms/step - accuracy: 0.4773 - loss: 1.5962 - val_accuracy: 0.8211 - val_loss: 1.0020\n",
      "Epoch 56/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 507ms/step - accuracy: 0.4873 - loss: 1.5992 - val_accuracy: 0.8596 - val_loss: 0.9464\n",
      "Epoch 57/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 508ms/step - accuracy: 0.4996 - loss: 1.5014 - val_accuracy: 0.8737 - val_loss: 0.9208\n",
      "Epoch 58/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 507ms/step - accuracy: 0.4865 - loss: 1.5192 - val_accuracy: 0.8596 - val_loss: 0.9930\n",
      "Epoch 59/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 513ms/step - accuracy: 0.4860 - loss: 1.5634 - val_accuracy: 0.8632 - val_loss: 0.8883\n",
      "Epoch 60/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 518ms/step - accuracy: 0.4796 - loss: 1.5867 - val_accuracy: 0.8456 - val_loss: 0.8821\n",
      "Epoch 61/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 516ms/step - accuracy: 0.5110 - loss: 1.5467 - val_accuracy: 0.8807 - val_loss: 0.8774\n",
      "Epoch 62/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 518ms/step - accuracy: 0.4615 - loss: 1.5894 - val_accuracy: 0.8982 - val_loss: 0.8890\n",
      "Epoch 63/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 514ms/step - accuracy: 0.5009 - loss: 1.5743 - val_accuracy: 0.8947 - val_loss: 0.8941\n",
      "Epoch 64/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 511ms/step - accuracy: 0.4777 - loss: 1.5894 - val_accuracy: 0.8947 - val_loss: 0.8320\n",
      "Epoch 65/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 525ms/step - accuracy: 0.5079 - loss: 1.5062 - val_accuracy: 0.8596 - val_loss: 0.8914\n",
      "Epoch 66/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 514ms/step - accuracy: 0.5330 - loss: 1.5543 - val_accuracy: 0.8772 - val_loss: 0.8584\n",
      "Epoch 67/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 507ms/step - accuracy: 0.4667 - loss: 1.5576 - val_accuracy: 0.8737 - val_loss: 0.8779\n",
      "Epoch 68/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 509ms/step - accuracy: 0.5146 - loss: 1.4447 - val_accuracy: 0.8140 - val_loss: 0.9091\n",
      "Epoch 69/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 513ms/step - accuracy: 0.4879 - loss: 1.4768 - val_accuracy: 0.8632 - val_loss: 0.8666\n",
      "Epoch 70/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 522ms/step - accuracy: 0.5114 - loss: 1.5083 - val_accuracy: 0.8877 - val_loss: 0.7624\n",
      "Epoch 71/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 513ms/step - accuracy: 0.5354 - loss: 1.3891 - val_accuracy: 0.7860 - val_loss: 0.9783\n",
      "Epoch 72/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 512ms/step - accuracy: 0.4751 - loss: 1.7040 - val_accuracy: 0.8737 - val_loss: 0.8290\n",
      "Epoch 73/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 528ms/step - accuracy: 0.5191 - loss: 1.4707 - val_accuracy: 0.9158 - val_loss: 0.8294\n",
      "Epoch 74/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 518ms/step - accuracy: 0.5015 - loss: 1.4616 - val_accuracy: 0.8456 - val_loss: 0.7694\n",
      "Epoch 75/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 516ms/step - accuracy: 0.4859 - loss: 1.5636 - val_accuracy: 0.9018 - val_loss: 0.7865\n",
      "Epoch 76/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 517ms/step - accuracy: 0.5245 - loss: 1.3876 - val_accuracy: 0.8947 - val_loss: 0.8116\n",
      "Epoch 77/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 522ms/step - accuracy: 0.5622 - loss: 1.3562 - val_accuracy: 0.8526 - val_loss: 0.8220\n",
      "Epoch 78/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 524ms/step - accuracy: 0.4857 - loss: 1.5478 - val_accuracy: 0.8982 - val_loss: 0.7713\n",
      "Epoch 79/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 519ms/step - accuracy: 0.5003 - loss: 1.4600 - val_accuracy: 0.8702 - val_loss: 0.7822\n",
      "Epoch 80/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 518ms/step - accuracy: 0.5368 - loss: 1.4514 - val_accuracy: 0.8772 - val_loss: 0.7543\n",
      "Epoch 81/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 515ms/step - accuracy: 0.5349 - loss: 1.3937 - val_accuracy: 0.8667 - val_loss: 0.6985\n",
      "Epoch 82/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 512ms/step - accuracy: 0.5220 - loss: 1.3929 - val_accuracy: 0.9088 - val_loss: 0.7154\n",
      "Epoch 83/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 509ms/step - accuracy: 0.5375 - loss: 1.3411 - val_accuracy: 0.8877 - val_loss: 0.7443\n",
      "Epoch 84/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 508ms/step - accuracy: 0.5262 - loss: 1.4133 - val_accuracy: 0.8772 - val_loss: 0.7368\n",
      "Epoch 85/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 510ms/step - accuracy: 0.5283 - loss: 1.3920 - val_accuracy: 0.8772 - val_loss: 0.7216\n",
      "Epoch 86/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 512ms/step - accuracy: 0.5357 - loss: 1.3733 - val_accuracy: 0.8421 - val_loss: 0.8417\n",
      "Epoch 87/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 510ms/step - accuracy: 0.5555 - loss: 1.3540 - val_accuracy: 0.8982 - val_loss: 0.6948\n",
      "Epoch 88/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 515ms/step - accuracy: 0.5327 - loss: 1.4352 - val_accuracy: 0.8526 - val_loss: 0.7999\n",
      "Epoch 89/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 516ms/step - accuracy: 0.5413 - loss: 1.3660 - val_accuracy: 0.9053 - val_loss: 0.7137\n",
      "Epoch 90/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 516ms/step - accuracy: 0.5248 - loss: 1.4373 - val_accuracy: 0.9123 - val_loss: 0.6880\n",
      "Epoch 91/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 515ms/step - accuracy: 0.5479 - loss: 1.3335 - val_accuracy: 0.8807 - val_loss: 0.7361\n",
      "Epoch 92/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 513ms/step - accuracy: 0.5180 - loss: 1.3692 - val_accuracy: 0.8912 - val_loss: 0.6772\n",
      "Epoch 93/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 516ms/step - accuracy: 0.5898 - loss: 1.2918 - val_accuracy: 0.8947 - val_loss: 0.7256\n",
      "Epoch 94/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 515ms/step - accuracy: 0.5664 - loss: 1.3120 - val_accuracy: 0.8982 - val_loss: 0.6871\n",
      "Epoch 95/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 509ms/step - accuracy: 0.5466 - loss: 1.3069 - val_accuracy: 0.8912 - val_loss: 0.7544\n",
      "Epoch 96/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 508ms/step - accuracy: 0.5438 - loss: 1.3797 - val_accuracy: 0.9123 - val_loss: 0.7150\n",
      "Epoch 97/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 511ms/step - accuracy: 0.5649 - loss: 1.3106 - val_accuracy: 0.8842 - val_loss: 0.7643\n",
      "Epoch 98/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 515ms/step - accuracy: 0.5600 - loss: 1.3024 - val_accuracy: 0.9193 - val_loss: 0.6626\n",
      "Epoch 99/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 516ms/step - accuracy: 0.5417 - loss: 1.3513 - val_accuracy: 0.8947 - val_loss: 0.7107\n",
      "Epoch 100/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 534ms/step - accuracy: 0.5591 - loss: 1.3104 - val_accuracy: 0.9158 - val_loss: 0.6942\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9793 - loss: 0.3920\n",
      "Model Loss: 0.44052833318710327, Model Accuracy: 0.9754385948181152\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define CNN Model\n",
    "def build_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=input_shape[0], activation='relu'))  # Increase the number of neurons\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))  # Output layer for classification\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Prepare the labels (make sure they are one-hot encoded)\n",
    "num_classes = 50   # Update this value to match the number of classes in your dataset\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)  # Assuming you have 'y_train' labels available\n",
    "\n",
    "# Build the model\n",
    "model = build_model(input_shape=(X_train_features.shape[1],), num_classes=num_classes)  # Update num_classes here\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_features, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_train_features, y_train)\n",
    "print(f\"Model Loss: {loss}, Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f5502b6-b27c-4b3b-a521-1e13656fb6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')  # Saves model as a single file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a992a8-b43b-46c7-8363-611ecb76d584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
